---
layout: mathpage
title: 感知器学习 
date: 2015-07-22
categories: 机器学习 自然语言处理
tags: 感知器
onewords: 感知器是神经网络与支持向量机的基础，引入了超平面的概念，使用了错误驱动+SGD的更新方式。是简单好用的分类方法。是一种判别模型。
---
> 感知器在数据集划分超平面做分类，模型参数包含权值向量 $$ w $$ 和偏移 $$ b $$  ;模型的损失函数定义了错分点到超平面的距离和；模型的更新机制是基于`错误驱动`的`SGD`方法。最后，感知器是一种线性分类方法，是判别模型。

##0. 基本思想

我们把数据表示为向量空间中的点（使用一个向量表示）。分类问题就是要将数据划分到相应类别，对应到向量空间，就是要划分数据点——如果是二元分类，我们就说将点划分为正例(POSITIVE)与负例(NEGATIVE)；如果是多元分类，我们输出一个标签(LABEL)。

感知器是在向量空间中构建一个或多个超平面，对数据点进行划分。如果是二元分类，只需要一个超平面即可。如果是多元分类 ,设类别数为N($$ N > 2 $$)，则需要N个超平面。

> 感知器的超平面思想，更一般的可以称为`线性分类面`、`线性决策边界`等。这种思想是SVM（支持向量机），NN（神经网络）的基础。

##1. 超平面定义

在向量空间（欧式空间）$$ \mathbb{R}^n $$中，定义 平面法向量$$ W \in \mathbb{R}^n $$ , 定义平面偏移 $$ b \in \mathbb{R}^1 $$ , 定义空间中的点（实例）$$ X \in \mathbb{R}^n $$ ， 则超平面可表示为： 

$$ y = W * X + b$$

>   欧式空间： 又称为欧几里得空间（Euclidean Space）。用$$ \mathbb{R} $$表示实数域，对任意一个正整数n，实数的n元组的全体构成了$$ \mathbb{R} $$上的一个n维向量空间，用$$ \mathbb{R}^n $$表示，有时称之为**实数坐标空间**(来自[维基百科](https://zh.wikipedia.org/wiki/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4)).*通俗的来说，初高中学习的二维坐标空间、三维立体空间都是欧式空间。*

###1.1 关于平面的一些强调

1. $$ y = W * X + b $$中，**W就是平面的法向量**。

2. 任意点到平面的距离：设点为$$ x \in \mathbb{R}^n $$ , 则点到平面$$ y = W * X + b $$的距离为 $$ D = \frac {\vert W*x + b \vert}{\Vert W \Vert_2}$$ （*即把x带入平面方程中求出的值取绝对值，除以平面法向量W的模（二范数）*） 。这也被称为**几何间隔** 。

##2.模型

###2.1 什么是模型

在监督学习过程中，模型就是要学习的概率分布或者决策函数。感知器所属的判别模型，通常是确定一个决策函数，来将输入映射到输出。

###2.2 感知器模型

####2.2.1 决策函数：

对于二元分类，
    
$$ y = sign(W*X + b) $$

其中sign函数定义为：

$$ sign(t) = \cases{ +1 \quad (t \gt 0) \\
-1 \quad (t \leq 0)  }$$


W是权值向量，即平面法向量 $$ W \in \mathbb{R}^n $$，b是偏移 , $$ b \in \mathbb{R} $$；
X是输入向量，$$ X \in \mathbb{R}^n $$ , y是输出label，$$ y \in \{-1,+1\} $$

对于多元分类,

$$ y_i = \arg_{i \in I} \max(W_i * X + b_i) $$

设输出类别数为$$ n $$ , 下标集合$$ I = \{ 0 , 1 , ... , n-1\} , i \in I $$ ，输出标签 $$ y_i \in \{y_0 , y_1 , ... , y_{n-1}\} $$ . 前面提到，n个类别，需要n个超平面。则对应的权值向量集合为$$ \{ W_0 , W_1 , ... , W_{n-1} \} $$ ，对应的b为$$ b \in \{ b_1 , b_2 , ... , b_{n-1} \}$$。

####2.2.2 直观定义

二元分类，把点带入平面，结果为正即为正例，否则为负例。

多元分类，取点到所有超平面中距离（严格来说，指带入平面方程的值，有正负）最大的超平面对应的标签作为输出。

##3.优化目标(损失函数)

> 这里仅考虑二元分类的情况。

感知器的损失函数，定义为**错分的点**到超平面的距离之和（即认为正确分类的点到超平面距离为0）。

前面提到点到超平面的距离为$$ D = \frac{1}{\Vert W \Vert_2} \vert W*X + b \vert $$ , 我们知道，所谓错分的点，即$$ y_{predict} = sign(W*X+b) $$与点的正确标签不同，即$$ y_{predict} != y $$ , 换句话说，即是

$$ \begin{align*}
y *& y_{predict} \leq 0\\
y *& (W*X +b) \leq 0\\
-y *& (W*X +b) \geq 0 ~且~  \vert y \vert = 1
\end{align*} $$ 

故我们可以将平面距离去掉绝对值，$$ D = - \frac{1}{\Vert W \Vert_2 } y ( W*X + b )$$ 。

令错分点的集合为$$ M $$ , 则错分点到超平面距离之和可以定义为： $$ D_M = - \frac{1}{\Vert W \Vert_2} \sum_{m \in M}{y_m(W*X_m + b)}$$

通常，我们将$$ \frac{1}{\Vert W \Vert_2} $$去掉，就得到了感知器的损失函数L：

$$ L(w , b) = - \sum_{m \in M}{W*X_m + b}$$

其中$$ M $$是错分点的集合。

> 将几何间隔$$ D = \frac{1}{\Vert W \Vert_2} \vert W*X + b \vert $$ 去掉$$ \frac{1}{\Vert W \Vert_2} $$ ，得到$$ {D}' = \vert W*X + b \vert  $$， 这也可以被称做**函数间隔**。

##4. 学习算法

所谓学习，就是为模型的参数找到一个合适的值，使得优化目标得到数据集上的最优（或局部最优）解（如果以损失函数作为优化，则是使损失函数值达到最小或局部最小）。

> 如果优化目标函数是一个凸函数或凹函数，即可以有全局最优；如果不是，则仅能保证有局部最优。

> 凸函数，形状类似二元函数且开口向上，有最小值；凹函数则类似二元函数开口向下，有最大值。

感知器使用`随机梯度下降(SGD , Stochastic Gradient Descent )`的方式来学习得到使得损失函数最小的`W`和`b`。当数据集可分时，学习到的参数能够使得损失为0（称为`学习算法收敛`）；如果不可分，则损失值在一定范围内波动。

> 当然还有其他的学习算法，如基于数学的最小二乘法（矩阵运算），还有其他的如BFGS , LBFGS等等。（PS：并不知道这些方法实际内容）

> 梯度下降法，是通过迭代，每次沿着梯度下降的方向移动一段距离，最终达到一个极值点的方法。梯度，就是导数；梯度下降的方向，数值上表示就是就是导数的相反数。常常再为导数相反数乘上一个 $$\eta $$ , 这也被称作学习因子(Learning Rate)。学习因子对于梯度下降而言还是比较重要的，因为这在一定程度上决定了每次梯度下降的距离。我们定义每次梯度下降的距离为$$ \Delta = - \nabla * \eta   $$ 。如果$$ \eta $$过大，则可能导致优化函数的值在极值点附近来回动荡；过小则会使迭代次数增加。故一般来说，未知情况下可以把$$ \eta $$设置稍小一些。一般说来，将$$ \eta $$设置为一个定值即可，因为导数是随参数变化而变化的，在极值点附近会自然比较小，在其他区域会比较大。当然，也有一些Ada方法，会根据最近导数变化的情况设置学习因子的值（一般在一个范围内变化），这在神经网络这种每次迭代开销很大的环境下使用还是很有增益的。**梯度下降根据更新频次的不同，可以分为三种。**第一种就是普通梯度下降,或者叫批量梯度下降（batch GD），在整个数据集上做梯度下降——以感知器为例，如果是普通梯度下降，那么便是将训练集中所有错分点全部过一遍后，将得到的损失函数求梯度做更新。这是从数学意义上最直观、最可信的做法。但是更新一次开销很大。第二种被称为小批量梯度下降(mini-batch GD , 中文名不准确)，就是把数据集分成N份，每份做完后就做一次梯度下降更新。最后就是随机梯度下降（SGD），每个对优化函数有影响的实例（在感知器中，是每个错分的实例）都会引起随机梯度下降的更新。这无疑更新频率提高了，但是针对一个实例的更新，是否对全局的优化函数更新有利？据张岳老师说某位大师穷其一生证明了其与普通GD等价。但是查资料却没有找到是具体哪位，有些唏嘘。

感知器的损失函数 $$ L(W,b) = -\sum_{m \in M}{y_m (W*X_m + b )}$$ , 使用SGD，只考虑一个实例，设$$ i \in M $$ , 则$$ X_i $$是错分实例，需要进行梯度下降更新。按照以下步骤：

1. 求$ W $ , $ b $ 在实例$$ x_i $$下的损失函数梯度（即对$ W $、$ b $求导）。
    
    对$ X_i $的损失函数为：$$ L(W,b,i) = -y_i (W * X_i + b) $$ ,

    对$ W $求导，有$$\frac{\partial L}{\partial W} = -y_i * X_i $$
    
    对$ b $求导，有$$\frac{\partial L}{\partial b} = -y_i $$

2. 更新

    设学习因子为$ \eta $ , 则：

    对$ W $ 更新：$$ W' = W - \eta * \frac{\partial L}{\partial W} = W + y_i  \eta  X_i $$

    对$ b $ 更新: $$ b' = b - \eta * \frac{\partial L}{\partial b} = b + y_i \eta $$

以上，就完成了一次SGD过程。在训练集上迭代，直到收敛（L = 0）或者在某个阈值内波动即可停止迭代，完成参数学习过程。

###4.1 学习算法的直观理解及对多元分类的扩展

以$ W $为例， $ W' = W + y_i \cdot \eta \cdot X_i $ , 可以理解为：对于正例，如果我们将其错分为负例，则我们将$ W $加上$ \eta \cdot X_i $ , $ \eta \cdot X_i  $向量中元素值均非负，这使得下次再划分该实例时，$ WX_i + b $的值会更偏向正一些，即向正确结果更靠近。对于负例的分析同理。

由此我们可以扩展出使用感知器进行多元分类的更新算法：

首先，对于多元分类，每个类别都有权值向量，而输出类别的确定方式为$ y_{predict} = \arg \max_y (W_y \cdot X + b ) $ ， 故如果错分，我们可以增加正确类别对应的权值，同时减少输出类别对应的权值项。经过这样地处理，下次进行$ \arg \max$运算时，感知器就能够向正确的结果靠近。这与二元分类更新算法的直观理解相同。

> 感知器将一个实例分类错误后，经过更新算法的更新，并不能保证修正后的参数能够立刻正确分类该实例，而仅仅能保证会向该正确结果靠近。这说明`更新算法是保守的而非主动的`<sup>[1]</sup>。

###4.2 伪代码

定义权值向量$ \vec W $ , 偏移 $ b $ (或$\vec b$ ) , 迭代次数$ N $ , 数据集$ {\rm T} = \{(\vec X_i , y_i)\}_{1}^M $ , 学习率 $ \eta $

1. 二元分类 

$\vec W \in \mathbb{R}^{1 \times n} $ , $ b \in \mathbb{R}^1 $(sigular , 常量) , $ \vec X_i \in \mathbb{R}^{n \times 1} $ , $ y \in \{-1 , +1 \} $ 

定义转置函数 TR

{% highlight python %}

binaryClassificationPerceptronTrain( W_0 , b_0 , N , T , eta ) :
    W = W_0
    b = b_0
    
    repeat N times :
        for ( X_i , y_i ) in T $ :
            y_predict = sign( W · X_i + b )
            if y_predict · y_i < 0 :
                W = W + y_i · eta · TR(X_i) # 转置
                b = b + y_i·eta 
    return W , b

{% endhighlight %}

2. 多元分类

$\vec W \in \mathbb{R}^{k \times n} $ , $ \vec b \in \mathbb{R}^{k \times 1} $ , $ \vec X_i \in \mathbb{R}^{n \times 1} $ , $ y \in L = \{l_0 , l_1 , \dots , l_k \} $ 

定义矩阵变换函数 G = get_corresponding_row(Matrix/Vector m  , label l ) , 将矩阵（向量）对应label行取出

定义矩阵变换函数 E = extend_variable(Vector/sigular v , label l) , 将向量（常数）向上扩展一维（可以认为是函数G的相反运算），对应label行为值为v，其余全部为0.

{% highlight python %}

multiClassificationPerceptronTrain(W_0 , b_0 , N , T , eta ) :
    W = W_0
    b = b_0 

    repeat N times :
        for ( X_i , y_i ) in T :
            y_predict = argmax_{y \in L}(G(W,y)·X_i + G(b , y) )
            if y_predict in not equal to y_i :
                W = W + E(eta·X_i , y_i) - E(eta·X_i , y_predict)
                b = b + E(eta , y_i ) - E(eta , y_predict)

    return W , b

{% endhighlight %}

[1] 感知器学习研究 ， 刘建伟 


