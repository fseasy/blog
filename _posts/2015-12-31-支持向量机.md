---
layout: mathpage
title: 支持向量机（SVM）
date: 2015-12-31
categories: 技术 机器学习 
tags: 支持向量机 最大间隔 合页损失 SMO
onewords: 本篇文章介绍SVM的在线性可分、线性不可分时基于最大间隔和合页损失(hinge loss)推导的优化目标，以及基于SMO的优化方法。
---
> 大名鼎鼎的SVM（支持向量机）算法，拥有较为坚实的数学基础，在很长一段时间内都是最佳分类器的代名词。本文以《统计学习方法》中支持向量机为主要学习资料，同时参考了vapnik发表的《support-vector networks》论文，力图较为清晰的描述SVM的优化目标（引出、推导）及优化方法。

本文的内容包括：

1. 最大间隔分类器的提出

2. SVM的优化目标

    1. 线性可分情况下的优化目标

    2. 线性不可分下优化目标

    3. 从合页损失的角度看优化目标

    4. 确认最终优化目标

3. 引入核方法

4. 优化方法（SMO）

    1. SMO思想

    2. 具体推导

    3. SMO总结

> 开始编辑时间2015-12-31 ，  预期编辑完成时间 2016-1-18 (有大量考试)


###最大间隔分类器的提出

TODO

###SVM的优化目标

TODO

###引入核方法

TODO

###优化方法

TODO

